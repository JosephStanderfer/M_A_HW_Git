trainsample=(sample==1)     # put 70% of the observations in the training sample
validsample=(sample==2)     # put the other 15% in the validation sample
predsample=(sample==3)      # put the other 15% in the validation sample
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# just plot data for one store
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
err1=(trop$lmove-pred1)    # compute the error = actual - predicted
# predict the validation sample using the model
pred1=predict(mdl1,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
sqerr1=(err1^2)            # compute the square of the error = error*error
abserr1=abs(err1)          # compute the absolute error = abs(error)
describeBy(cbind(err1,sqerr1,abserr1),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+cheapest+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+trop$lessThanMM + trop$lessThanFG + trop$lessThanHH + trop$lessThanTF + trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+trop$lessThanMM + trop$lessThanFG + trop$lessThanHH + trop$lessThanTF + trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+ trop$lessThanFG + trop$lessThanHH + trop$lessThanTF + trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+ trop$lessThanHH + trop$lessThanTF + trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean +trop$lessThanpureTrop + trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+trop$lessThanHS+feat+disp,data=trop[trainsample,]) )
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+lessThanMM + lessThanFG + lessThanHH + lessThanTF + lessThanpureTrop + lessThanHS+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+lessThanMM + lessThanFG + lessThanHH + lessThanTF + lessThanpureTrop+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+ lessThanHH + lessThanTF + lessThanpureTrop+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+ lessThanTF+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+cheapest+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+promo+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+store*perCheaperThanMean+promo+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+promo+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+promo+store*lprice+perCheaperThanMean+promo+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+promo+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (store model)
# notice since store is a factor it will include store specific intercepts
#        store*lprice means to include a separate lprice coefficient for each store
#( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
( mdl2=lm(lmove~store+store*lprice+perCheaperThanMean+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
#per store model
( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
# setup library
setwd("C:/Users/josep/OneDrive/Documents/GitHub/M_A_HW_Git/Assignment3/data")
if (!require(psych)) {install.packages("psych"); library(psych)}
# import data
#setwd("C:\Users\sprih\OneDrive\Desktop\Marketing Analytics\M_A_HW_Git\Assignment3\data")
rfjdata=read.csv(file="rfjdata.csv")    # weekly sales and price for each product and store
rfjstore=read.csv(file="rfjstore.csv")  # store information
rfjupc=read.csv(file="rfjupc.csv")      # product information
rfjdemo=read.csv(file="rfjdemo.csv")    # demographic information about stores
rfjdate=read.csv(file="rfjdate.csv")    # dates for each week
print(dim(rfjdemo))
# remove blank stores
rfjdemo=rfjdemo[!is.na(rfjdemo$mmid),]
print(dim(rfjdemo))
# recode store and upc as factors
rfjdata$store=as.factor(rfjdata$store)
rfjdata$upc=as.factor(rfjdata$upc)
rfjdemo$store=as.factor(rfjdemo$store)
rfjupc$upc=as.factor(rfjupc$upc)
# transform the data by adding log price and log move
rfjdata$lprice=log(rfjdata$price)
rfjdata$lmove=log(rfjdata$move)
# let's create a subset of the data for just tropicana premium
trop=rfjdata[which(rfjdata$upc==4850000102 & rfjdata$price>0 & rfjdata$move>0),]
#add minute maid price comparison into trop data
competitor=rfjdata[which(rfjdata$upc==2500002606 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "MMlprice", "MMmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanMM <- trop$MMlprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$MMpercCheaper <- (trop$MMlprice - trop$lprice) / trop$MMlprice
#Florida Gold
competitor=rfjdata[which(rfjdata$upc==1110000142 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "FGlprice", "FGmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanFG <- trop$FGlprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$FGpercCheaper <- (trop$FGlprice - trop$lprice) / trop$FGlprice
#HH OJ
competitor=rfjdata[which(rfjdata$upc==3828154001 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "HHlprice", "HHmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanHH <- trop$HHlprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$HHpercCheaper <- (trop$HHlprice - trop$lprice) / trop$HHlprice
#TreeFresh OJ
competitor=rfjdata[which(rfjdata$upc==7271850001 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "TFlprice", "TFmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanTF <- trop$TFlprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$TFpercCheaper <- (trop$TFlprice - trop$lprice) / trop$TFlprice
#Trop pure prm
competitor=rfjdata[which(rfjdata$upc==4850000139 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "pureTroplprice", "pureTropmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanpureTrop <- trop$pureTroplprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$pureTroppercCheaper <- (trop$pureTroplprice - trop$lprice) / trop$pureTroplprice
#trop homestyle
competitor=rfjdata[which(rfjdata$upc==4850000139 & rfjdata$price>0 & rfjdata$move>0),]
myvars <- c("store", "week", "lprice","lmove")
competitor = competitor[myvars]
colnames(competitor) <- c("store", "week", "HSlprice", "HSmove")
trop <- merge(x = trop, y = competitor, by=c("store","week"))
#create binary row of whether tropicana is cheaper than MM
trop$lessThanHS <- trop$HSlprice > trop$lprice
#find comparative price difference (percentage lower than MM)
trop$HSpercCheaper <- (trop$HSlprice - trop$lprice) / trop$HSlprice
trop$perCheaperThanMean <- (((trop$MMlprice+trop$FGlprice+trop$HHlprice+trop$TFlprice+trop$pureTroplprice+trop$HSlprice)/6) - trop$lprice) / trop$lprice
trop$cheapest <- (trop$lessThanMM & trop$lessThanFG & trop$lessThanHH & trop$lessThanTF & trop$lessThanpureTrop & trop$lessThanHS)
# set the random number seed to the samples will be the same when re-run
nobs=nrow(trop)
set.seed(1248765792)
sample = sample.int(3, size=nobs, prob=c(.7,.15,.15), replace=TRUE)  # randomly split data into 3 groups
trainsample=(sample==1)     # put 70% of the observations in the training sample
validsample=(sample==2)     # put the other 15% in the validation sample
predsample=(sample==3)      # put the other 15% in the validation sample
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# just plot data for one store
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred1=predict(mdl1,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err1=(trop$lmove-pred1)    # compute the error = actual - predicted
sqerr1=(err1^2)            # compute the square of the error = error*error
abserr1=abs(err1)          # compute the absolute error = abs(error)
describeBy(cbind(err1,sqerr1,abserr1),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
#per store model
( mdl2=lm(lmove~store+store*lprice+feat+disp,data=trop[trainsample,]) )
# plot the results
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line
coef=mdl2$coefficients[c("(Intercept)","disp","feat","store5","lprice","store5:lprice")]  # extract the coefficients
abline(a=coef[1]+mean(trop$disp)*coef[2]+mean(trop$feat)*coef[3]+coef[4],
b=coef[5]+coef[6],col="blue")
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred2=predict(mdl2,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err2=(trop$lmove-pred2)    # compute the error = actual - predicted
sqerr2=(err2^2)            # compute the square of the error = error*error
abserr2=abs(err2)          # compute the absolute error = abs(error)
describeBy(cbind(err2,sqerr2,abserr2),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
## log linear model (pooled model)
( mdl1=lm(lmove~lprice+feat+disp,data=trop[trainsample,]) )
# plot all data
plot(lmove~lprice,data=trop)
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# just plot data for one store
plot(lmove~lprice,data=trop[which(trop$store==5),])
# overlay regression line (adjust the intercept by the average effect of the non-price variables)
abline(a=mdl1$coefficients["(Intercept)"]+mean(trop$disp)*mdl1$coefficients["disp"]+mean(trop$feat)*mdl1$coefficients["feat"],
b=mdl1$coefficients["lprice"])
# predict the validation sample using the model
pred1=predict(mdl1,newdata=trop,type='response')      # compute the predictions using the previous estaimtes
err1=(trop$lmove-pred1)    # compute the error = actual - predicted
sqerr1=(err1^2)            # compute the square of the error = error*error
abserr1=abs(err1)          # compute the absolute error = abs(error)
describeBy(cbind(err1,sqerr1,abserr1),group=sample,fast=TRUE)   # summarize the various measures of errors for the training and validation samples
