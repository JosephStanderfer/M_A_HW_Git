install.packages("tidyverse", dependencies=TRUE)
library(installr)
#initial installations
install.packages("installr", dependencies=TRUE)
#load those packages into R
library(tidyverse)
#load those packages into R
#library(tidyverse)
library(installr)
#To check for newest versions of R and packages
updateR()
# prepare data
if (!require(datasets)) {install.packages("datasets"); library(datasets)}
data("iris")    # load the data into memory
# summarize the dataset
summary(iris)
# first look at the data
head(iris)
# plot iris data in boxplot
par(mfrow=c(4,1),mar=c(3,4,1,1))  # mfrow=c(4,1) tells R to plot 4 rows and 1 column, and mar is the margin
boxplot(Petal.Length~Species,data=iris,ylab="Petal Length")
boxplot(Petal.Width~Species,data=iris,ylab="Petal Width")
boxplot(Sepal.Length~Species,data=iris,ylab="Sepal Length")
boxplot(Sepal.Width~Species,data=iris,ylab="Sepal Width")
par(mfrow=c(1,1))  # reset to one graph in the panel
parallelplot(~iris[1:4]|Species,data=iris)
# scatterplot matrix plots an array of scatterplots
splom(~iris[1:4], groups = Species, data = iris)
# one more visualization is a parallel lines plot
if (!require(lattice)) {install.packages("lattice"); library(lattice)}
# the ~ ... | ... in the following line is a formula in R, and says the input variables
# are the first four columns of iris and are conditional upon the category Species
parallelplot(~iris[1:4]|Species,data=iris)
# scatterplot matrix plots an array of scatterplots
splom(~iris[1:4], groups = Species, data = iris)
# the ~ ... | ... in the following line is a formula in R, and says the input variables
# are the first four columns of iris and are conditional upon the category Species
parallelplot(~iris[1:4]|Species,data=iris)
newiris=iris
newiris$Species = NULL
set.seed(1248765792)   # set the seed so the random initialization of the clusters is the same
( kc = kmeans(newiris, 3) )
kc$cluster
kc['cluster']
kc$centers
mean(iris$Sepal.Length[kc$cluster==1])
str(kc)
# plot the clusters and their centers. Note that there are four dimensions
# in the data and that only the first two dimensions are used to draw the plot
# below.  Some black points close to the green center (asterisk) are actually
# closer to the black center in the four dimensional space
# scatter plot of each cluster with a different color for each cluster
par(mar=c(5,5,5,5))
plot(newiris[c("Sepal.Length", "Sepal.Width")], col=kc$cluster)
points(kc$centers[,c("Sepal.Length", "Sepal.Width")], col=1:3, pch=8, cex=2) # overlay the cluster centroids as asterisks
legend("topright",legend=as.character(1:3),col=1:3,pch=8,bty='n') # add legend to tell which colors correspond with which cluster
# look at the cluster solution
print(kc$centers)  # the centers or centroids are the averages of observation within a cluster
#mean(newiris$Sepal.Length[kc$cluster==1])   # example: compute average of variable for specific cluster
# we can use parallel plot to see the effects, the auto.key plots a legend above the parallellines
parallelplot(iris[1:4],groups=iris$Species,main="Species",auto.key=list(space="top",columns=3,lines=T))
parallelplot(iris[1:4],groups=kc$cluster,main="Clusters",auto.key=list(space="top",columns=3,lines=T))
# compare the Species label with the cluster result
table(iris$Species, kc$cluster)
getpwd()
pwd()
cwd()
getwd()
# import dataset from file (change the directory to where your data is stored)
setwd("C:/Users/oldye/Documents/CMU_2018/Spring2019/MarketingAnalytics_95832/HW_Git/M_A_HW_Git/Assignment7") #!! change to your directory !!
###############################################################################
# setup environment, make sure this library has been installed
if (!require(tree)) {install.packages("tree"); library(tree)}
# setup environment (if you want to use fancy tree plots)
if (!require(rpart)) {install.packages("rpart"); library(rpart)}
# data manipulation
if (!require(plyr)) {install.packages("plyr"); library(plyr)}
# better describe
if (!require(psych)) {install.packages("psych"); library(psych)}
###############################################################################
### read in the data and prepare the dataset for analysis
###############################################################################
# import dataset from file (change the directory to where your data is stored)
setwd("C:/Users/oldye/Documents/CMU_2018/Spring2019/MarketingAnalytics_95832/HW_Git/M_A_HW_Git/Assignment7") #!! change to your directory !!
cell2cell=read.csv("cell2cell_data.csv")
# set the random number seed so the samples will be the same if regenerated
set.seed(1248765792)
# prepare new values
trainsample=(cell2cell$Sample==1)
validsample=(cell2cell$Sample==2)
predsample=(cell2cell$Sample==3)
plotsample=sample(1:nrow(cell2cell),200)
# remove sample from the cell2cell set, since we have the sample variables
cell2cell$Sample=NULL
# recode the location so that we only keep the first 3 characters of the region
# and only remember the areas with more than 800 individuals, otherwise set the
# region to OTH for other
origcsa=cell2cell$Csa
newcsa=substr(as.vector(cell2cell$Csa),1,3)
csasize=xtabs(~newcsa)
csasizename=rownames(csasize)
for (i in 1:length(csasize)) {
if (csasize[i]<=800) {
newcsa[newcsa==csasizename[i]]="OTH"
}
}
# overwrite the original Sca variable with the newly recoded variable
cell2cell$Csa=factor(newcsa)
# recode missing age1 and age2 values as their mean
# and create an age1miss and age2miss variable
age1=as.vector(cell2cell$Age1)  # create a local copy with just values
age2=as.vector(cell2cell$Age2)
age1[is.na(age1)]=0  # replace missing values with 0
age2[is.na(age2)]=0
age1miss=((age1==0)+0)  # create an indicator for missing age values (which are 0)
age2miss=((age2==0)+0)
age1[age1==0]=mean(age1[age1>0])  # recode missing value values as the mean
age2[age2==0]=mean(age2[age2>0])
cell2cell$Age1=age1   # save the variables
cell2cell$Age1miss=age1miss
cell2cell$Age2=age2
cell2cell$Age2miss=age2miss
# replace missing values with means
for (i in 1:ncol(cell2cell)) {
if (typeof(cell2cell[,i])=="double") {
cell2cell[is.na(cell2cell[,i]),i]=mean(cell2cell[,i],na.rm=T)
}
}
###############################################################################
### estimate your model (either tree or logistic)
### only estimates the model, does not do any diagnostics or statistics
### you must save your model to "mymodel" for the rest of the script
### !! use your best model from part 1
###############################################################################
# this logistic regression uses some important variables and is a gives a good model
# notice that this "." only refers to the variables in mvarlist, not all variables
mymodel = glm(Churn~Eqpdays+Retcall+Months+Overage+Mou+Changem,data=cell2cell[trainsample,],family='binomial')
# this gives tree model
#mymodel = rpart(Churn~., data=cell2cell[trainsample,], control=rpart.control(cp=0.005))
# give a summary of the model's trained parameters
summary(mymodel)
###############################################################################
### compute adjusted probabilities and LTV in the full dataset
###
### hint:
### you may want to create new campaigns as below for offerA
### you can then decide which offer to select for each user by looking to
### see which offer gives you the maximum return
###############################################################################
# set common values for computing ltv
irate=.05/12  # annual discount rate
adja=.5/.02; adjb=.5/.98  # save the adjustments for a and b when computing adjusted churn
### offer (none): compute predictions using your model (for all users)
if ("rpart" %in% class(mymodel)) {
pchurn.unadj=predict(mymodel,newdata=cell2cell,type='vector')
} else {
pchurn.unadj=predict(mymodel,newdata=cell2cell,type='response')
}
# now adjust predictions to project probability of churn in the original data
a=pchurn.unadj/adja
b=(1-pchurn.unadj)/adjb
pchurn=a/(a+b)
# compute LTV
ltv.unadj=cell2cell$Revenue*(1+irate)/(1+irate-(1-pchurn.unadj))
ltv=cell2cell$Revenue*(1+irate)/(1+irate-(1-pchurn))
cost=rep(0,length(pchurn))
### offer A: offer a free phone
cell2cell.offerA=cell2cell   # create a new copy of data
cell2cell.offerA$Eqpdays=0   # simulate effect of free phone
# compute predictions using model for all users
if ("rpart" %in% class(mymodel)) {
pchurn.offerA=predict(mymodel,newdata=cell2cell.offerA,type='vector')
} else {
pchurn.offerA=predict(mymodel,newdata=cell2cell.offerA,type='response')
}
# now adjust predictions to project probability of churn in the original data
a=pchurn.offerA/adja
b=(1-pchurn.offerA)/adjb
pchurn.offerA=a/(a+b)
# compute LTV for new offer (assumes cost of new phone is $200)
cost.offerA=rep(200,length(pchurn.offerA))  # assume $200 cost for every customer
ltv.offerA=cell2cell.offerA$Revenue*(1+irate)/(1+irate-(1-pchurn.offerA))-cost.offerA
### offer (new)
# if you want to create a new offer use offer A as a template
# compare original churn and adjusted (!! if you create more offers include them in result below)
result=cbind(pchurn.unadj,pchurn,pchurn.offerA,ltv.unadj,ltv,ltv.offerA,cost,cost.offerA)
head(result)
summary(result)
###############################################################################
### save the results to a file
###############################################################################
# create list of users to evaluate
userlist=1:nrow(cell2cell)   # use this line for full dataset
#userlist=c(119,240,30,32)   # uncomment this list for just our four selected users
#set.seed(123); userlist=sample(1:nrow(cell2cell),100)  # uncomment this line for random sample of 100 users
# create vector of variables used in model called mvarlist, and add other variables that we want to write out
# these lines require mymodel to be defined above, must either be rpart or glm
if ("rpart" %in% class(mymodel)) {
mvarlist=names(mymodel$variable.importance)   # get the list of variables from rpart by looking at the importance
} else {
mvarlist=names(coefficients(mymodel))[-1]     # get the variables used in your logistic regression moodel, except the intercept which is in first position
}
evarlist=c("Customer","Revenue")     # vector of extra variables to save -- regardless of whether they are in the model
varlist=c(mvarlist,evarlist)         # vector of variable names that we will use (all model variables plus ID and revenue)
print(varlist)  # vector of variables to save
# retrieve data about the users  (model.matrix may not work for complex trees)
if ("rpart" %in% class(mymodel)) {
modeldata=as.data.frame(cell2cell[userlist,mvarlist])      # extract the variables directly from the data
} else {
modeldata=model.matrix(mymodel,data=cell2cell[userlist,])   # construct the data used in the model
}
userdata=cell2cell[userlist,evarlist]  # extract the additional variables that we want
userdata=cbind(modeldata,userdata)  # change to dataframe
print(userdata)   # print out user data
head(userdata)
# combine results with userdata and write to augmented result
augresult=cbind(userdata,result[userlist,])  # only selects user in userlist
head(augresult)
# create a table with all the data (this is helpful if you want to work with the data in excel)
write.csv(augresult,file="cell2cell_results.csv")   # if you want you can import this file into excel for easier processing
# import dataset from file (change the directory to where your data is stored)
setwd("C:/Users/oldye/Documents/CMU_2018/Spring2019/MarketingAnalytics_95832/HW_Git/M_A_HW_Git/Assignment7") #!! change to your directory !!
cell2cell=read.csv("cell2cell_data.csv")
###############################################################################
### read in the data and prepare the dataset for analysis
###############################################################################
# import dataset from file (change the directory to where your data is stored)
setwd("C:/Users/oldye/Documents/CMU_2018/Spring2019/MarketingAnalytics_95832/HW_Git/M_A_HW_Git/Assignment7") #!! change to your directory !!
cell2cell=read.csv("cell2cell_data.csv")
# set the random number seed so the samples will be the same if regenerated
set.seed(1248765792)
# prepare new values
trainsample=(cell2cell$Sample==1)
validsample=(cell2cell$Sample==2)
predsample=(cell2cell$Sample==3)
plotsample=sample(1:nrow(cell2cell),200)
# remove sample from the cell2cell set, since we have the sample variables
cell2cell$Sample=NULL
# recode the location so that we only keep the first 3 characters of the region
# and only remember the areas with more than 800 individuals, otherwise set the
# region to OTH for other
origcsa=cell2cell$Csa
newcsa=substr(as.vector(cell2cell$Csa),1,3)
csasize=xtabs(~newcsa)
csasizename=rownames(csasize)
for (i in 1:length(csasize)) {
if (csasize[i]<=800) {
newcsa[newcsa==csasizename[i]]="OTH"
}
}
# overwrite the original Sca variable with the newly recoded variable
cell2cell$Csa=factor(newcsa)
# recode missing age1 and age2 values as their mean
# and create an age1miss and age2miss variable
age1=as.vector(cell2cell$Age1)  # create a local copy with just values
age2=as.vector(cell2cell$Age2)
age1[is.na(age1)]=0  # replace missing values with 0
age2[is.na(age2)]=0
age1miss=((age1==0)+0)  # create an indicator for missing age values (which are 0)
age2miss=((age2==0)+0)
age1[age1==0]=mean(age1[age1>0])  # recode missing value values as the mean
age2[age2==0]=mean(age2[age2>0])
cell2cell$Age1=age1   # save the variables
cell2cell$Age1miss=age1miss
cell2cell$Age2=age2
cell2cell$Age2miss=age2miss
# replace missing values with means
for (i in 1:ncol(cell2cell)) {
if (typeof(cell2cell[,i])=="double") {
cell2cell[is.na(cell2cell[,i]),i]=mean(cell2cell[,i],na.rm=T)
}
}
###############################################################################
### estimate your model (either tree or logistic)
### only estimates the model, does not do any diagnostics or statistics
### you must save your model to "mymodel" for the rest of the script
### !! use your best model from part 1
###############################################################################
# this logistic regression uses some important variables and is a gives a good model
# notice that this "." only refers to the variables in mvarlist, not all variables
mymodel = glm(Churn~Eqpdays+Retcall+Months+Overage+Mou+Changem,data=cell2cell[trainsample,],family='binomial')
# this gives tree model
#mymodel = rpart(Churn~., data=cell2cell[trainsample,], control=rpart.control(cp=0.005))
# give a summary of the model's trained parameters
summary(mymodel)
###############################################################################
### compute adjusted probabilities and LTV in the full dataset
###
### hint:
### you may want to create new campaigns as below for offerA
### you can then decide which offer to select for each user by looking to
### see which offer gives you the maximum return
###############################################################################
# set common values for computing ltv
irate=.05/12  # annual discount rate
adja=.5/.02; adjb=.5/.98  # save the adjustments for a and b when computing adjusted churn
### offer (none): compute predictions using your model (for all users)
if ("rpart" %in% class(mymodel)) {
pchurn.unadj=predict(mymodel,newdata=cell2cell,type='vector')
} else {
pchurn.unadj=predict(mymodel,newdata=cell2cell,type='response')
}
# now adjust predictions to project probability of churn in the original data
a=pchurn.unadj/adja
b=(1-pchurn.unadj)/adjb
pchurn=a/(a+b)
# compute LTV
ltv.unadj=cell2cell$Revenue*(1+irate)/(1+irate-(1-pchurn.unadj))
ltv=cell2cell$Revenue*(1+irate)/(1+irate-(1-pchurn))
cost=rep(0,length(pchurn))
### offer A: offer a free phone
cell2cell.offerA=cell2cell   # create a new copy of data
cell2cell.offerA$Eqpdays=0   # simulate effect of free phone
# compute predictions using model for all users
if ("rpart" %in% class(mymodel)) {
pchurn.offerA=predict(mymodel,newdata=cell2cell.offerA,type='vector')
} else {
pchurn.offerA=predict(mymodel,newdata=cell2cell.offerA,type='response')
}
# now adjust predictions to project probability of churn in the original data
a=pchurn.offerA/adja
b=(1-pchurn.offerA)/adjb
pchurn.offerA=a/(a+b)
# compute LTV for new offer (assumes cost of new phone is $200)
cost.offerA=rep(200,length(pchurn.offerA))  # assume $200 cost for every customer
ltv.offerA=cell2cell.offerA$Revenue*(1+irate)/(1+irate-(1-pchurn.offerA))-cost.offerA
### offer (new)
# if you want to create a new offer use offer A as a template
# compare original churn and adjusted (!! if you create more offers include them in result below)
result=cbind(pchurn.unadj,pchurn,pchurn.offerA,ltv.unadj,ltv,ltv.offerA,cost,cost.offerA)
head(result)
summary(result)
###############################################################################
### save the results to a file
###############################################################################
# create list of users to evaluate
userlist=1:nrow(cell2cell)   # use this line for full dataset
#userlist=c(119,240,30,32)   # uncomment this list for just our four selected users
#set.seed(123); userlist=sample(1:nrow(cell2cell),100)  # uncomment this line for random sample of 100 users
# create vector of variables used in model called mvarlist, and add other variables that we want to write out
# these lines require mymodel to be defined above, must either be rpart or glm
if ("rpart" %in% class(mymodel)) {
mvarlist=names(mymodel$variable.importance)   # get the list of variables from rpart by looking at the importance
} else {
mvarlist=names(coefficients(mymodel))[-1]     # get the variables used in your logistic regression moodel, except the intercept which is in first position
}
evarlist=c("Customer","Revenue")     # vector of extra variables to save -- regardless of whether they are in the model
varlist=c(mvarlist,evarlist)         # vector of variable names that we will use (all model variables plus ID and revenue)
print(varlist)  # vector of variables to save
# retrieve data about the users  (model.matrix may not work for complex trees)
if ("rpart" %in% class(mymodel)) {
modeldata=as.data.frame(cell2cell[userlist,mvarlist])      # extract the variables directly from the data
} else {
modeldata=model.matrix(mymodel,data=cell2cell[userlist,])   # construct the data used in the model
}
userdata=cell2cell[userlist,evarlist]  # extract the additional variables that we want
userdata=cbind(modeldata,userdata)  # change to dataframe
print(userdata)   # print out user data
head(userdata)
# combine results with userdata and write to augmented result
augresult=cbind(userdata,result[userlist,])  # only selects user in userlist
head(augresult)
# create a table with all the data (this is helpful if you want to work with the data in excel)
write.csv(augresult,file="cell2cell_results.csv")   # if you want you can import this file into excel for easier proc
